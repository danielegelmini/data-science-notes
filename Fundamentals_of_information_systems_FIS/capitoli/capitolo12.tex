\chapter{The Master Theorem for Solving Recurrences}

\section{Introduction}

The \textbf{Master Theorem} provides a systematic way to analyze divide-and-conquer recurrences of the form:  
\[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]
where:
\begin{itemize}
    \item \(a \geq 1\): Number of subproblems.
    \item \(b > 1\): Factor by which the input size is divided in each recursive step.
    \item \(f(n)\): Cost outside the recursive calls, often referred to as the "work" term.
\end{itemize}
The theorem helps determine the asymptotic complexity of \(T(n)\) without solving the recurrence fully. The theorem can not be applied if:
\begin{itemize}
    \item T(n) is not monotone, for example T(n) = sinx
    \item f(n) is not polynomial, for example f(n) = $2^x$
    \item b cannot be expressed as a constant, for example T(n) = T($\sqrt{n}$)
\end{itemize}

\section{Cases of the Master Theorem}

Let \(c = \log_b a\), representing the growth rate of the recursive tree. The complexity of \(T(n)\) depends on the relationship between \(f(n)\) and \(n^c\):

\subsection{Case 1: \(f(n) = O(n^{c - \epsilon})\)}
If \(f(n)\) grows slower than \(n^c\) by a polynomial factor (\(\epsilon > 0\)), then:  
\[
T(n) = \Theta(n^c)
\]

\subsection{Case 2: \(f(n) = \Theta(n^c)\)}
If \(f(n)\) and \(n^c\) grow at the same rate, then:  
\[
T(n) = \Theta(n^c \log n)
\]
The general formula is that if f(n) = $\theta(n^c log^kn)$ and \(f(n)\) and \(n^c\) grow at the same rate, then:
\[
T(n) = \Theta(n^c \log^{k+1}n)
\]

\subsection{Case 3: \(f(n) = \Omega(n^{c + \epsilon})\)}
If \(f(n)\) grows faster than \(n^c\) by a polynomial factor (\(\epsilon > 0\)) and the \textit{regularity condition} \(a f(\frac{n}{b}) \leq cf(n)\) (for \(c < 1\) and n sufficiently large) holds, then:  
\[
T(n) = \Theta(f(n))
\]

\subsection{Key notes:}
This theorem says that we choose the larger function comparing our $f(n)$ with $n^{\log_b a}$. The first case says $n^{\log_b a}$ is larger than $f(n)$ because we can equalize $f(n)$ to $n^{\log_b a}$ by subtracting a possible epsilon greater than zero. If we can do it then we have the first case. The last case says that $f(n)$ is larger than $n^{\log_b a}$ then $T(n) = \Theta(f(n))$. The second case says that the two functions are the same  $\rightarrow T(n) = \Theta(n^{\log_b a}\log n)$. If we are between cases we can not use the master theorem, if we are lucky we will know the answer immediately with the master theorem.


\section{Examples}

\subsection{Strassen's Algorithm}
\[
T(n) = 7T\left(\frac{n}{2}\right) + \Theta(n^2)
\]
\begin{itemize}
    \item \(a = 7\), \(b = 2\), \(f(n) = n^2\).
    \item \(c = \log_2 7 \approx 2.807\).
    \item Compare \(f(n) = n^2\) to \(n^{\log_2 7}\): \(f(n) = O(n^{c - \epsilon})\), \(\epsilon = 0.807\).
\end{itemize}
By Case 1:  
\[
T(n) = \Theta(n^{\log_2 7})
\]

\subsection{Example: \(T(n) = 9T(n/3) + n\)}
\begin{itemize}
    \item \(a = 9\), \(b = 3\), \(f(n) = n\).
    \item \(c = \log_3 9 = 2\).
    \item \(f(n) = O(n^{c - 1})\).
\end{itemize}
By Case 1:  
\[
T(n) = \Theta(n^2)
\]

\subsection{Example: \(T(n) = T(2n/3) + 1\)}
\begin{itemize}
    \item \(a = 1\), \(b = 3/2\), \(f(n) = 1\).
    \item \(c = \log_{3/2} 1 = 0\).
    \item \(f(n) = \Theta(1)\).
\end{itemize}
By Case 2:  
\[
T(n) = \Theta(\log n)
\]
We look if $n^{\log_{\frac{3}{2}} 1} = n^0 = 1$, since they are equal we are in case 2, therefore $T(n) = \Theta(n^{\log_b a} \log n) = \Theta(n^{\log_{\frac{3}{2}} 1} \log n) = \Theta(\log n)$ since the $n^x$ term is equal to one!

\subsection{Exercise: \(T(n) = 3T(n/4) + n \log n\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 3\), \(b = 4\), \(f(n) = n \log n\).
        \item \(n^{\log_b a} = n^{\log_4 3} = n^{0.792}\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item \(f(n) = \Omega(n^{\log_4 3 + \epsilon})\), with \(\epsilon \approx 0.2\).
        \item Check the regularity condition:
        \[
        af\left(\frac{n}{b}\right) = 3 \left(\frac{n}{4}\right) \log\left(\frac{n}{4}\right) \leq \frac{3}{4}n \log(n) = cf(n), \quad c = \frac{3}{4}.
        \]
        \item Regularity condition holds as \(c < 1\).
    \end{itemize}
    \item Conclusion: By the third case of the Master Theorem:
    \[
    T(n) = \Theta(n \log n).
    \]
\end{itemize}

\subsection{Exercise: \(T(n) = 2T(n/2) + n \log n\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 2\), \(b = 2\), \(f(n) = n \log n\).
        \item \(n^{\log_b a} = n^{\log_2 2} = n\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Compare \(f(n)\) and \(n^{\log_b a}\):
        \[
        \frac{f(n)}{n^{\log_b a}} = \frac{n \log n}{n} = \log n.
        \]
        \item \(\log n < n^\epsilon\) asymptotically, but \(f(n)\) is not polynomially larger than \(n^{\log_b a}\).
    \end{itemize}
    \item Conclusion: The Master Theorem cannot be applied since \(f(n)\) is between the second and third case.
\end{itemize}

\subsection{Exercise 3: \(T(n) = 2T(n/2) + \frac{n}{\log n}\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 2\), \(b = 2\), \(f(n) = \frac{n}{\log n}\).
        \item \(n^{\log_b a} = n^{\log_2 2} = n\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Compare \(f(n)\) and \(n^{\log_b a}\):
        \[
        \frac{f(n)}{g(n)} = \frac{\frac{n}{\log n}}{n} = \frac{1}{\log n}.
        \]
        \item As \(n \to \infty\), \(\frac{1}{\log n} \to 0\), so \(f(n) = O(n)\).
        \item Check if \(f(n) = O(n^{\log_b a - \epsilon})\):
        \[
        \lim_{n \to \infty} \frac{\frac{n}{\log n}}{n^{1-\epsilon}} = \frac{n^\epsilon}{\log n} \to \infty, \quad \text{(using L'Hôpital's Rule)}.
        \]
        \item Therefore, \(f(n)\) is not polynomially smaller than \(n\), and we are between cases.
    \end{itemize}
    \item Conclusion: The Master Theorem cannot be applied since \(f(n)\) is between cases 1 and 2.
\end{itemize}





\section{Exercises}

\subsection{Exercise 1: \(T(n) = 8T(n/2) + 1000n^2\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 8\), \(b = 2\), \(f(n) = 1000n^2\).
        \item \(n^{\log_b a} = n^{\log_2 8} = n^3\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Check if \(f(n) = O(n^{3-\epsilon})\):
        \[
        c n^2 = O(n^{3-\epsilon}) \quad \text{for any } 0 < \epsilon < 1.
        \]
        \item Since \(f(n)\) satisfies the condition, we conclude \(T(n) = \Theta(n^3)\).
        \item Verify if \(f(n)\) is polynomially smaller:
        \[
        \lim_{n \to \infty} \frac{c n^2}{n^{3-\epsilon}} = \frac{\infty}{\infty}.
        \]
        Using L'Hôpital's Rule:
        \[
        \lim_{n \to \infty} \frac{2c n}{(3-\epsilon)n^{2-\epsilon}} = 0.
        \]
        Thus, \(f(n)\) is polynomially smaller.
    \end{itemize}
    \item Conclusion:
    \[
    T(n) = \Theta(n^3).
    \]
\end{itemize}

\subsection{Exercise 2: \(T(n) = 2T(n/2) + 10n\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 2\), \(b = 2\), \(f(n) = \Theta(n)\).
        \item \(n^{\log_b a} = n^{\log_2 2} = n\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Since \(f(n) = \Theta(n)\), it satisfies the second case of the Master Theorem.
    \end{itemize}
    \item Conclusion:
    \[
    T(n) = \Theta(n \log n).
    \]
\end{itemize}

\subsection{Exercise 3: \(T(n) = 2T(n/2) + 10n^2\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 2\), \(b = 2\), \(f(n) = 10n^2\).
        \item \(n^{\log_b a} = n^{\log_2 2} = n\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Check if \(f(n) = \Omega(n^{1+\epsilon})\): Yes.
        \item Verify the regularity condition:
        \[
        2 \cdot \frac{n^2}{2} < c \cdot 10n^2, \quad c < 1.
        \]
        The condition is satisfied. Because it results that $c > \frac{1}{2}$.
    \end{itemize}
    \item Conclusion:
    \[
    T(n) = \Theta(f(n)) = \Theta(n^2).
    \]
\end{itemize}

\subsection{Exercise 4: \(T(n) = 4T(n/2) + \frac{n^2}{\log n}\)}

\begin{itemize}
    \item Parameters:
    \begin{itemize}
        \item \(a = 4\), \(b = 2\), \(f(n) = \frac{n^2}{\log n}\).
        \item \(n^{\log_b a} = n^{\log_2 4} = n^2\).
    \end{itemize}
    \item Analysis:
    \begin{itemize}
        \item Check if \(f(n) = O(n^{2-\epsilon})\):
        \[
        \lim_{n \to \infty} \frac{\frac{n^2}{\log n}}{n^2} = \frac{1}{\log n} \to 0.
        \]
        \(f(n)\) grows slower than \(n^2\).
        \item Check if \(f(n)\) is polynomially smaller:
        \[
        \lim_{n \to \infty} \frac{\frac{n^2}{\log n}}{n^{2-\epsilon}} = \frac{n^\epsilon}{\log n} = \frac{\infty}{\infty}.
        \]
        Using L'Hôpital's Rule:
        \[
        \lim_{n \to \infty} \frac{\epsilon n^{\epsilon - 1}}{\frac{1}{n}} = \infty.
        \]
        \(f(n)\) is not polynomially smaller.
    \end{itemize}
    \item Conclusion:
    \[
    \text{The Master Theorem cannot be applied, as \(f(n)\) is between cases 1 and 2.}
    \]
\end{itemize}

\section{Proof of the Master Theorem}

\subsection{Theorem for Exact Powers of \(b > 1\)}

We start by proving the theorem for exact powers of \(b > 1\) such that \(n = 1, b, b^2, \ldots\).

\[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]

This proof is structured around three lemmas:

\begin{enumerate}
    \item \textbf{Lemma 1:} Reduces the recurrence to an equation involving a summation.
    \item \textbf{Lemma 2:} Provides asymptotic bounds for this summation.
    \item \textbf{Lemma 3:} Combines the results of the first two lemmas to prove the Master Theorem.
\end{enumerate}

\subsection{Lemma 1}

Let \(a \geq 1\) and \(b > 1\) be constants, and let \(f(n)\) be a non-negative function defined on exact powers of \(b\). Define \(T(n)\) by the recurrence:

\[
T(n) =
\begin{cases} 
\Theta(1) & \text{if } n = 1, \\
aT\left(\frac{n}{b}\right) + f(n) & \text{if } n = b^i, i \in \mathbb{N}.
\end{cases}
\]

Then, 

\[
T(n) = \Theta\left(n^{\log_b a}\right) + \sum_{j=0}^{\log_b n - 1} a^j f\left(\frac{n}{b^i}\right).
\]

\paragraph{Proof of Lemma 1:}
We construct a recursion tree to analyze the recurrence.

\begin{forest}
    for tree={
        grow'=south, 
        circle, 
        draw, 
        minimum size=1.2em, 
        inner sep=1pt, 
        s sep+=10pt, 
        l sep+=10pt
    }
    [
        \(f(n)\) 
        [\(a f\left(\frac{n}{b}\right)\)
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
        ]
        [\(a f\left(\frac{n}{b}\right)\)
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
        ]
        [\(a f\left(\frac{n}{b}\right)\)
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
            [\(a^2 f\left(\frac{n}{b^2}\right)\)
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
                [\(\cdots\)
                    [\(\Theta(1)\)]
                ]
            ]
        ]
    ]
\end{forest}


The cost of this algorithm is given by:
\begin{itemize}
    \item The root contributes \(f(n)\).
    \item The second level contributes \(a f(n/b)\).
    \item The third level contributes \(a^2 f(n/b^2)\).
    \item The \(i\)-th level contributes \(a^i f(n/b^i)\).
    \item The leaves contribute \(\Theta\left(n^{\log_b a}\right)\).
\end{itemize}
Summing the contributions from all levels:

\[
T(n) = \sum_{j=0}^{\log_b a - 1} a^j f\left(\frac{n}{b^j}\right) + \Theta\left(n^{\log_b a}\right).
\]

The terms represent the cost of the internal levels and the cost of the leaves, respectively. The Master Theorem distinguishes between cases where:
\begin{itemize}
    \item The cost of the leaves dominates.
    \item The cost of the root dominates.
    \item The costs are balanced.
\end{itemize}

\subsection{Lemma 2}

Let \(a > 1\), \(b > 1\), and \(f(n)\) be a non-negative function defined on exact powers of \(b\). Define the star function \(g(n)\) as:

\[
g(n) = \sum_{j=0}^{\log_b n - 1} a^j f\left(\frac{n}{b^j}\right).
\]

Asymptotic bounds for \(g(n)\) are as follows:
\begin{enumerate}
    \item If \(f(n) = O(n^{\log_b a - \epsilon})\), \(\epsilon > 0\), then \(g(n) = O(n^{\log_b a})\).
    \item If \(f(n) = \Theta(n^{\log_b a})\), then \(g(n) = \Theta(n^{\log_b a} \log n)\).
    \item If \(af(n/b) < c f(n)\), \(c < 1\), and for all \(n \geq b\), then \(g(n) = \Theta(f(n))\).
\end{enumerate}

\paragraph{Case 1:}
Assume \(f(n) = O(n^{\log_b a - \epsilon})\), \(\epsilon > 0\). Then:

\[
f\left(\frac{n}{b^j}\right) = O\left(\left(\frac{n}{b^j}\right)^{\log_b a - \epsilon}\right).
\]

Substituting into the summation:

\[
g(n) = O\left(\sum_{j=0}^{\log_b n - 1} a^j \left(\frac{n}{b^j}\right)^{\log_b a - \epsilon}\right).
\]

Simplify:

\[
g(n) = O\left(n^{\log_b a - \epsilon} \sum_{j=0}^{\log_b n - 1} \left(\frac{a}{b^{\log_b a - \epsilon}}\right)^j\right).
\]

The sum is a geometric series:

\[
\sum_{j=0}^{\log_b n - 1} \left(\frac{a}{b^{\log_b a - \epsilon}}\right)^j = O(n^{\epsilon}).
\]

Thus:

\[
g(n) = O(n^{\log_b a}).
\]

\paragraph{Case 2:}
Assume \(f(n) = \Theta(n^{\log_b a})\). Substituting into the summation:

\[
g(n) = \Theta\left(\sum_{j=0}^{\log_b n - 1} a^j \left(\frac{n}{b^j}\right)^{\log_b a}\right).
\]

Simplify:

\[
g(n) = \Theta\left(n^{\log_b a} \sum_{j=0}^{\log_b n - 1} 1\right).
\]

\[
g(n) = \Theta(n^{\log_b a} \log n).
\]

\paragraph{Case 3:}
If \(af(n/b) < c f(n)\), \(c < 1\), then iterating \(j\) times:

\[
f\left(\frac{n}{b^j}\right) \leq \left(\frac{c}{a}\right)^j f(n).
\]

Substituting into the summation:

\[
g(n) = \sum_{j=0}^{\log_b n - 1} a^j \left(\frac{c}{a}\right)^j f(n).
\]

This simplifies to:

\[
g(n) = O(f(n)).
\]

\subsection{Lemma 3}

Combining Lemma 1 and Lemma 2, \(T(n)\) can be bounded asymptotically as follows:
\begin{enumerate}
    \item If \(f(n) = O(n^{\log_b a - \epsilon})\), then \(T(n) = \Theta(n^{\log_b a})\).
    \item If \(f(n) = \Theta(n^{\log_b a})\), then \(T(n) = \Theta(n^{\log_b a} \log n)\).
    \item If \(f(n) = \Omega(n^{\log_b a + \epsilon})\) and \(af(n/b) \leq cf(n)\), \(c < 1\), then \(T(n) = \Theta(f(n))\).
\end{enumerate}

\paragraph{Proof of lemma 3}
From Lemma 1, we know:
\[
T(n) = \Theta(n^{\log_b a}) + \sum_{j=0}^{\log_b n -1} a^j f\left(\frac{n}{b^j}\right)
\]

\subsubsection{Case 1: \(f(n) = O(n^{\log_b a - \epsilon})\) with \(\epsilon > 0\)}
From Lemma 2, we get:
\[
\sum_{j=0}^{\log_b n - 1} f\left(\frac{n}{b^j}\right) = O(n^{\log_b a})
\]
Therefore:
\[
T(n) = \Theta(n^{\log_b a}) + O(n^{\log_b a}) = \Theta(n^{\log_b a})
\]

\subsubsection{Case 2: \(f(n) = \Theta(n^{\log_b a})\)}
From Lemma 2, we have:
\[
\sum_{j=0}^{\log_b n - 1} a^j f\left(\frac{n}{b^j}\right) = \Theta(n^{\log_b a} \log n)
\]
Substituting this back:
\[
T(n) = \Theta(n^{\log_b a}) + \Theta(n^{\log_b a} \log n) = \Theta(n^{\log_b a} \log n)
\]

\subsubsection{Case 3: \(f(n) = \Omega(n^{\log_b a + \epsilon})\) with \(\epsilon > 0\)}
From Lemma 2:
\[
\sum_{j=0}^{\log_b n - 1} a^j f\left(\frac{n}{b^j}\right) = \Theta(f(n))
\]
Thus:
\[
T(n) = \Theta(n^{\log_b a}) + \Theta(f(n))
\]
Since \(f(n) = \Omega(n^{\log_b a + \epsilon})\), \(f(n)\) dominates. Therefore:
\[
T(n) = \Theta(f(n))
\]

\subsubsection{Proof for Floor and Ceiling Cases}
To handle:
\[
T(n) = aT\left(\left\lceil \frac{n}{b} \right\rceil \right) + f(n)
\]
and:
\[
T(n) = aT\left(\left\lfloor \frac{n}{b} \right\rfloor \right) + f(n)
\]

The lower bound is derived straightforwardly. Now, we prove the upper bound for:
\[
T(n) = aT\left(\left\lceil \frac{n}{b} \right\rceil \right) + f(n)
\]
This is a recursive problem:
\begin{itemize}
    \item At the root, we start with \(n\).
    \item At the next level, we get \(\lceil n/b \rceil\), followed by \(\lceil \lceil n/b \rceil / b \rceil\), and so on.
\end{itemize}
The size of the problem at level \(j\) is:
\[
n_j = 
\begin{cases} 
n & \text{if } j = 0 \\
\lceil n_{j-1}/b \rceil & \text{if } j > 0 
\end{cases}
\]

\subsubsection{Height of the Recursion Tree}
We aim to determine the depth \(k\) where \(n_k\) is a constant:
\[
n_j \leq \frac{n}{b^j} + \sum_{i=0}^{j-1} \frac{1}{b^i}
\]
Using the geometric series formula:
\[
n_j \leq \frac{n}{b^j} + \frac{b}{b-1}
\]
At the last level (\(j = \lfloor \log_b n \rfloor\)), the size of the problem becomes:
\[
n_{j} \leq \frac{n}{b^{\lfloor \log_b n \rfloor}} + \frac{b}{b-1}
\]
Thus, at depth \(\lfloor \log_b n \rfloor\), the size is \(O(1)\).

\subsubsection{Cost Analysis}
Now, evaluate the total cost:
\[
g(n) = \sum_{j=0}^{\lfloor \log_b n \rfloor - 1} a^j f(n_j)
\]
If \(a f(\lceil n/b \rceil) \leq c f(n)\) for \(n > b + \frac{b}{b-1}\) and \(c < 1\), we have:
\[
a^j f(n_j) \leq c^j f(n)
\]
Thus:
\[
g(n) \leq \sum_{j=0}^{\lfloor \log_b n \rfloor - 1} c^j f(n) < f(n) \sum_{j=0}^{\infty} c^j
\]
For \(c < 1\), the geometric series converges:
\[
g(n) = O(f(n))
\]


